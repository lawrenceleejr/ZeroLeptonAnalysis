Details on the output of -p

In this example we will look more closely at the output of the hypothesis tests we just run in order to understand better what '-p' is doing. Understanding the output of '-p' is very helpful in case there are problems. 

Let's look at the log file:

less out.log

1. Free fit of the background + signal model

Starting from the line containing

<INFO> ConfigManager: Created Fit Config: SPlusB

we see the configuration file read in. In this case we do not need to build the workspace (as we have done it earlier), so the next steps in already specific to calling '-p'. 
First, '-p' first runs a free fit:

<INFO> ConfigMgrCPP: Processing analysis Sig

which concludes with the fit result:

  RooFitResult: minimized FCN value: -0.650645, estimated distance to minimum: 3.58326e-06
                covariance matrix quality: Full, accurate covariance matrix
                Status : MINIMIZE=0 

    Floating Parameter    FinalValue +/-  Error   
  --------------------  --------------------------
                  Lumi    1.0000e+00 +/-  3.88e-02
             alpha_cor   -6.6577e-04 +/-  9.93e-01
             alpha_ucb    1.8890e-04 +/-  9.93e-01
             alpha_ucs   -6.7408e-05 +/-  9.93e-01
  gamma_stat_UserRegion_cuts_bin_0    1.0002e+00 +/-  2.22e-01
                mu_Sig    4.0056e-01 +/-  6.67e-01

This first fit is done using the FreeFit function in src/Utils.cxx. This function executes a slightly simplified fit in comparison to the standard '-f' option. The main difference is that all channels included in the workspace will be fitted, regardless if control, validation or signal region. The purpose of first executing some free fit of the background + signal model is to give the user some indication on if the hypothesis tests following might be affected by fit failures or not. We can store the result of the free fit in an external file for later use. (Similar fit results are in fact used in the step 'Creating a list file' in Part 5 below.)

2. Hypothesis tests

After the free fit HistFitter hands over to RootStats code and the further output depends on which test statistics and calculator type were chosen. E.g. in this example we have used the so-called asymptotic calculator (configMgr.calculatorType=2) and an one-sided profile likelihood test statistics (configMgr.testStatType=3).

The sequence of various hypothesis tests starts with the lines:

<INFO> HypoTestTool: >>> Running HypoTestInverter on the workspace combined
<INFO> HypoTestTool: >>> Setting up HypoTestInverter on the workspace combined
<INFO> HypoTestTool: >>> Setting up HypoTestCalculator on the workspace <combined>
<INFO> HypoTestTool: >>> Setting up HypoTest for : exclusion
<INFO> HypoTestTool: Using data set obsData

which informs you that
a) you are calculating some exclusion limits (and not a discovery sensitivity)
b) make the hypothesis tests on observed data

Then, another free fit is performed which determines the best fitted values for all nuisance and normalization parameters:

Info in <StandardHypoTestInvDemo>:  Doing a first fit to the observed data

which concludes with 

<INFO> HypoTestTool: StandardHypoTestInvDemo - Best Fit value : mu_Sig = 0.404772 +/- 0.629833

and

[#1] INFO:ObjectHandling -- RooWorkspace::saveSnaphot(combined) replacing previous snapshot with name ModelConfig__snapshot

This last line informs you that the new fitted values are attached to the signal+background model in a 'snapshot'.

Only after this fit is concluded, the asymptotic calculator is constructed.
The various processes that the asymptotic calculator runs can be looked up in https://root.cern.ch/root/html534/src/RooStats__AsymptoticCalculator.cxx.html#v0jbIC and in https://root.cern.ch/root/html534/src/RooStats__AsymptoticCalculator.cxx.html#Rua8gE

This can be summarized as:

* Part 1: Setting up the asymptotic calculator and building the Asimov dataset:

a) Evaluate the unconditional NLL for the full model on observed data

  In the log file this part starts with

  [#0] PROGRESS:Eval -- AsymptoticCalculator: Find  best unconditional NLL on observed data

  and concludes with

  [#0] PROGRESS:Eval -- Best fitted POI value = 0.401324 +/- 0.667405

b) Compute the Asimov data set for the background hypothesis

  This part starts with 

  [#0] PROGRESS:Eval -- AsymptoticCalculator: Building Asimov data Set

  and evaluates the best-fitted values for the nuisance parameters and a signal strength of 0.

c) Evaluate the likelihood on Asimov data just built

  This part starts with 

  [#0] PROGRESS:Eval -- AsymptoticCalculator: Find  best conditional NLL on ASIMOV data set for given alt POI ( mu_Sig ) = 0

Part 1 concludes with

<INFO> HypoTestTool: >>> Done setting up HypoTestCalculator on the workspace combined

* Part 2: Executing the hypothesis tests

Part 2 starts with the message:

<INFO> HypoTestTool: Doing a fixed scan  in interval : 1 , 1

(telling us that we will only test a signal strength of 1 but no other one. This is the main difference to the upper limit calculation in which multiple signal strengths are considered. Apart from this the upper limit calculation with '-l' is really pretty similar.)
Again, we have various parts:

d) Make a conditional fit of background+signal model on observed data.

  You see this in the log file after the message:

  [#1] INFO:Eval -- AsymptoticCalculator::GetHypoTest: - perform  an hypothesis test for  POI ( mu_Sig ) = 1
  [#0] PROGRESS:Eval -- AsymptoticCalculator::GetHypoTest -  Find  best conditional NLL on OBSERVED data set .....

e) Now we do a similar fit on the Asimov data set.
  
  You see this part starting from 

  [#0] PROGRESS:Eval -- AsymptoticCalculator::GetHypoTest -- Find  best conditional NLL on ASIMOV data set .... 

Using the results of the last two steps the CLs value is calculated:

[#0] PROGRESS:Eval -- P values for  mu_Sig =  1
        CLs      = 0.301765 +/- 0
        CLb      = 0.736093 +/- 0
        CLsplusb = 0.222127 +/- 0

If there is a failure in '-p' it is important to understand which of the six (!) fits done is the failing one. This particular fit can then be rebuild outside of '-p' and debugged further. We will explain this in an example in the advanced tutorial. 



Rebuilding fits of '-p'

We have seen in 'Details on the output pf -p' that various fits are performed when running hypothesis tests with '-p', among those:
- a free fit of the background + signal model
- a fit with the signal strength fixed to 1
- a fit with the signal strength fixed to 0

If one or multiple of these fits fail, no or no reliable CLs value can be calculated. Typical problems that lead to failures are:
- the background + signal model is very complicated and there are (fit) instabilities related to systematic uncertainties,
- the signal contribution is very large in comparison to a very small background prediction and very little observed data.

When the calculation of the CLs value is failing it is mandatory for the user to check first the log file to understand which of the fits done in '-p' is really failing. Afterwards, the user can try to rebuild this fit, using the functionalities HistFitter provides for '-f'. For technical reasons '-f' can provide a little bit more verbose output than '-p', which is helpful for debugging any problematic fit. In addition, the user can make before- and after-fit plots and correlations matrices which can also give some hints.

We don't have really complicated background+signal models in the tutorial and we also tried to make sure that none of our examples is failing. (Although this depends a little bit on the actual Root version used.) Therefore, in the following we will try to reproduce the fits done in the example 'Details on the output pf -p' to illustrate on how to rebuild fits outside of '-p'. Of course, you can also take one of your private problematic models and try to debug this along the lines described in this exercise. (Your tutor is happy to help you with any questions regarding problems appearing there.)

If you have not done so yesterday, please create the log file of the example 'Details on the output pf -p':

HistFitter.py -p analysis/tutorial/MyUserAnalysis.py 2>&1 | tee out.log

We will use this log file to check the results we get in the fits rebuilt.

1. The option '-C' in HistFitter

This option allows to fix certain parameters to a values provided by the user in a fit done with '-f'. The syntax is

-C parameter1:value1,parameter2:value2,... etc.

Also see the examples below.

2. Reproducing a fit of '-p' with the signal strength fixed to 0.

For this just run:

HistFitter.py -f -C "mu_Sig:0." analysis/tutorial/MyUserAnalysis.py

The fit result of this is:

  RooFitResult: minimized FCN value: -0.273073, estimated distance to minimum: 0.00027612
                covariance matrix quality: Full, accurate covariance matrix
                Status : MINIMIZE=0 HESSE=0 

    Constant Parameter    Value     
  --------------------  ------------
  binWidth_obs_x_UserRegion_cuts_0    1.0000e+00
  binWidth_obs_x_UserRegion_cuts_1    1.0000e+00
                mu_Sig    0.0000e+00
         nom_alpha_cor    0.0000e+00
         nom_alpha_ucb    0.0000e+00
         nom_alpha_ucs    0.0000e+00
  nom_gamma_stat_UserRegion_cuts_bin_0    1.0000e+00
           nominalLumi    1.0000e+00

    Floating Parameter  InitialValue    FinalValue +/-  Error     GblCorr.
  --------------------  ------------  --------------------------  --------
                  Lumi    1.0000e+00    1.0000e+00 +/-  3.88e-02  0.000000
             alpha_cor    0.0000e+00    1.5405e-01 +/-  9.69e-01  0.122812
             alpha_ucb    0.0000e+00    2.4486e-01 +/-  9.00e-01  0.185254
             alpha_ucs    0.0000e+00    0.0000e+00 +/-  9.93e-01  0.000000
  gamma_stat_UserRegion_cuts_bin_0    1.0000e+00    1.0614e+00 +/-  1.98e-01  0.190423


Comparing to out.log, you see that this fit result is pretty similar to the fit done in b) and c), although not identical. The reason for the small differences are small differences in the fit options that are used in '-f' and in '-p'. Most importantly, the luminosity was fixed and did not change in '-f'. If you are interested in the other more subtle differences, don't hesitate to ask your tutor. For the common practice, the two fit results are close enough.

3. Reproducing a fit of '-p' with the signal strength set to 1.

Run:

HistFitter.py -f -C "mu_Sig:1." analysis/tutorial/MyUserAnalysis.py

You should get the following result:

  RooFitResult: minimized FCN value: -0.35802, estimated distance to minimum: 9.17589e-06
                covariance matrix quality: Full, accurate covariance matrix
                Status : MINIMIZE=0 HESSE=0 

    Constant Parameter    Value     
  --------------------  ------------
  binWidth_obs_x_UserRegion_cuts_0    1.0000e+00
  binWidth_obs_x_UserRegion_cuts_1    1.0000e+00
                mu_Sig    1.0000e+00
         nom_alpha_cor    0.0000e+00
         nom_alpha_ucb    0.0000e+00
         nom_alpha_ucs    0.0000e+00
  nom_gamma_stat_UserRegion_cuts_bin_0    1.0000e+00
           nominalLumi    1.0000e+00

    Floating Parameter  InitialValue    FinalValue +/-  Error     GblCorr.
  --------------------  ------------  --------------------------  --------
                  Lumi    1.0000e+00    9.9878e-01 +/-  3.88e-02  0.038996
             alpha_cor    0.0000e+00   -2.1561e-01 +/-  9.67e-01  0.230151
             alpha_ucb    0.0000e+00   -1.7437e-01 +/-  9.85e-01  0.196699
             alpha_ucs    0.0000e+00   -8.2217e-02 +/-  9.93e-01  0.099913
  gamma_stat_UserRegion_cuts_bin_0    1.0000e+00    9.0940e-01 +/-  1.94e-01  0.282557

Comparing to out.log you see that this is pretty similar to the result obtained in e).

The fit in f) uses an Asimov set and also a signal strength of 1. Also this fit can be rebuild, essentially using the HistFitter option '-a', but it is a little bit more tricky. Ask your tutor in case you're interested.

The other fits in '-p' are free fits of the background+signal model and can be easily rebuild by using the standard '-f' option without using the option '-C'.

For all these examples you can also create plots and correlation matrices etc. using the options '-d' and '-D'.


